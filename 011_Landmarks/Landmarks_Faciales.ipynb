{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1Ix2gyn2FXje2CFHY-AWJTe5rA8HVZFZD","timestamp":1746658719118}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#¿Qué son los Landmarks Faciales?\n","\n","Imaginen que queremos \"marcar\" los puntos más importantes de un rostro. ¿Cuáles serían? Las esquinas de los ojos, la punta de la nariz, las comisuras de los labios, la forma de la mandíbula, etc.\n","\n","Los Landmarks Faciales son precisamente eso: un conjunto de puntos específicos predefinidos que representan características clave de un rostro humano en una imagen. Piensen en ellos como un \"mapa\" detallado de la cara.\n","\n","<img src=\"https://ai.google.dev/static/mediapipe/images/solutions/face_landmarker_keypoints.png?hl=es-419\" alt=\"Puntos clave de detección facial\" width=\"40%\">"],"metadata":{"id":"23gVQTH4E7Re"}},{"cell_type":"markdown","source":["## ¿Para qué sirven?\n","\n","Tener este \"mapa\" de puntos en un rostro es increíblemente útil en Visión por Computadora para muchísimas aplicaciones:\n","\n","** Alineación de rostros: Normalizar la posición y orientación de las caras para que estén siempre mirando al frente y centradas, facilitando otras tareas como el reconocimiento facial.\n","\n","** Análisis de expresiones: Detectar si alguien está sonriendo, sorprendido, enojado, basándose en la posición relativa de los puntos (especialmente alrededor de la boca y los ojos).\n","\n","** Filtros y efectos (¡como los de Instagram o Snapchat!): Superponer objetos virtuales (anteojos, sombreros, máscaras) de forma precisa sobre el rostro.\n","\n","** Realidad Aumentada: Anclar elementos virtuales al rostro en tiempo real.\n","\n","** Animación: Mover personajes digitales basándose en los movimientos de un actor real.\n","\n","** Medición de distancias: Calcular distancias entre puntos para análisis forenses o médicos.\n","\n","En resumen, los landmarks faciales nos dan una forma estructurada de entender la geometría y la pose de un rostro en una imagen.\n","\n","**¡Manos a la obra!** Encontrando Landmarks\n","Vamos a usar una biblioteca de Google llamada MediaPipe. MediaPipe es genial porque nos da \"soluciones\" listas para usar para tareas comunes de visión por computadora y aprendizaje automático, ¡como detectar landmarks faciales!\n","\n","También usaremos OpenCV (cv2), que es la biblioteca estándar para manejar imágenes en Python."],"metadata":{"id":"FbbJ6kqnIBp6"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"45XungcjE6IY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746658225350,"user_tz":180,"elapsed":30973,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"b6b60a04-76d3-42c8-912d-bde6c17fd314"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Collecting numpy\n","  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-2.2.5\n","Collecting mediapipe\n","  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n","Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n","Collecting numpy<2 (from mediapipe)\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n","Collecting protobuf<5,>=4.25.3 (from mediapipe)\n","  Downloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n","Collecting sounddevice>=0.4.4 (from mediapipe)\n","  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n","Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n","Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n","Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading protobuf-4.25.7-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n","Installing collected packages: protobuf, numpy, sounddevice, mediapipe\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 5.29.4\n","    Uninstalling protobuf-5.29.4:\n","      Successfully uninstalled protobuf-5.29.4\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.2.5\n","    Uninstalling numpy-2.2.5:\n","      Successfully uninstalled numpy-2.2.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n","grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n","ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed mediapipe-0.10.21 numpy-1.26.4 protobuf-4.25.7 sounddevice-0.5.1\n"]}],"source":["# Instalamos mediapipe (generalmente ya está instalado en Colab)\n","# La exclamación al principio indica que es un comando de terminal\n","!pip install --upgrade numpy\n","!pip install mediapipe opencv-python"]},{"cell_type":"code","source":["# Importamos las bibliotecas que vamos a usar\n","import cv2 # Para manejar imágenes (leer, mostrar, dibujar)\n","import mediapipe as mp # La biblioteca que hace la magia de encontrar los puntos\n","# Esta es una función especial para mostrar imágenes en Google Colab\n","from google.colab.patches import cv2_imshow\n","\n","print(\"Bibliotecas importadas correctamente.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3IbHUBofKBcW","executionInfo":{"status":"ok","timestamp":1746658253920,"user_tz":180,"elapsed":6684,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"6bc058fd-812c-4108-bcc0-9947e9bd659b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Bibliotecas importadas correctamente.\n"]}]},{"cell_type":"code","source":["# Necesitamos una imagen de un rostro para probar.\n","# Vamos a descargar una desde internet.\n","# Si queres, podes subir tu propia foto a Colab y cambiar el nombre del archivo.\n","\n","# URL de una imagen de ejemplo con un rostro simple\n","image_url = \"https://images.unsplash.com/photo-1500648767791-00dcc994a43e?q=80&w=1974&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\"\n","# Nombre con el que guardaremos el archivo en Colab\n","image_path = \"rostro_ejemplo.jpg\"\n","\n","print(f\"Descargando imagen desde: {image_url}\")\n","try:\n","    # Usamos una función simple para descargar el archivo\n","    import urllib.request\n","    urllib.request.urlretrieve(image_url, image_path)\n","    print(f\"Imagen descargada como: {image_path}\")\n","except Exception as e:\n","    print(f\"¡Error al descargar la imagen! {e}\")\n","    print(\"\\nPor favor, sube una imagen de un rostro a la sesión de Colab manualmente.\")\n","    print(\"Puedes hacerlo haciendo click en el ícono de la carpeta a la izquierda y arrastrando tu archivo.\")\n","    print(f\"Luego, asegúrate de que el archivo se llame '{image_path}' o cambia 'image_path' a tu nombre de archivo.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QUITzGXpIlM4","executionInfo":{"status":"ok","timestamp":1746658320260,"user_tz":180,"elapsed":80,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"5020d4be-dbaf-4f8e-8fb5-c4ad9ca06b6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Descargando imagen desde: https://images.unsplash.com/photo-1500648767791-00dcc994a43e?q=80&w=1974&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\n","Imagen descargada como: rostro_ejemplo.jpg\n"]}]},{"cell_type":"code","source":["# Ahora vamos a cargar la imagen que descargamos (o subiste)\n","# OpenCV la lee y la guarda en una variable 'imagen'\n","imagen = cv2.imread(image_path)\n","\n","# Verificamos si la imagen se cargó correctamente\n","if imagen is None:\n","    print(f\"¡Error! No se pudo cargar la imagen desde {image_path}.\")\n","    print(\"Asegúrate de que el archivo exista en el entorno de Colab y el nombre sea correcto.\")\n","else:\n","    print(\"Imagen cargada correctamente.\")\n","    # Mostramos las dimensiones de la imagen (ancho x alto)\n","    print(f\"Dimensiones de la imagen: {imagen.shape[1]} píxeles de ancho x {imagen.shape[0]} píxeles de alto.\")\n","\n","    # MediaPipe funciona mejor con imágenes en formato RGB (Rojo, Verde, Azul)\n","    # Pero OpenCV las carga en BGR (Azul, Verde, Rojo).\n","    # Hacemos la conversión necesaria.\n","    imagen_rgb = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n","    print(\"Imagen convertida a formato RGB para MediaPipe.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oAyTtZVIIstA","executionInfo":{"status":"ok","timestamp":1746658376176,"user_tz":180,"elapsed":189,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"98f4b715-4a7d-4441-efb7-81d01ad662fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Imagen cargada correctamente.\n","Dimensiones de la imagen: 1974 píxeles de ancho x 2960 píxeles de alto.\n","Imagen convertida a formato RGB para MediaPipe.\n"]}]},{"cell_type":"code","source":["# Aquí le decimos a MediaPipe que use su \"solución\" para encontrar puntos faciales.\n","# mp.solutions.face_mesh contiene el modelo pre-entrenado.\n","# FaceMesh es la clase que usamos para crear el detector.\n","# static_image_mode=True: Le decimos que procese una imagen estática (no un video).\n","# max_num_faces=1: Le decimos que solo busque un rostro para simplificar.\n","# refine_landmarks=True: Intenta hacer los puntos un poco más precisos.\n","# min_detection_confidence=0.5: Solo considera un rostro si está seguro al menos en un 50%.\n","mp_face_mesh = mp.solutions.face_mesh.FaceMesh(\n","    static_image_mode=True,\n","    max_num_faces=1,\n","    refine_landmarks=True,\n","    min_detection_confidence=0.5)\n","\n","print(\"Detector de puntos faciales inicializado.\")\n","\n","# Ahora procesamos la imagen. MediaPipe busca rostros y, si encuentra, sus puntos.\n","print(\"Procesando la imagen para encontrar puntos...\")\n","resultados = mp_face_mesh.process(imagen_rgb)\n","\n","# Una vez que terminamos de usar el detector, lo liberamos\n","mp_face_mesh.close()\n","\n","print(\"Procesamiento completado.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RB5SzSZXIypR","executionInfo":{"status":"ok","timestamp":1746658607244,"user_tz":180,"elapsed":115,"user":{"displayName":"BARRETO MATÍAS","userId":"15011433883683359534"}},"outputId":"a689f3a9-7fec-4f59-f600-2434cfffc9a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Detector de puntos faciales inicializado.\n","Procesando la imagen para encontrar puntos...\n","Procesamiento completado.\n"]}]},{"cell_type":"code","source":["# Creamos una copia de la imagen original para dibujar sobre ella\n","# Así no modificamos la imagen original\n","imagen_con_puntos = imagen.copy()\n","\n","# Obtenemos las dimensiones de la imagen (alto y ancho)\n","alto, ancho, _ = imagen.shape\n","\n","# Verificamos si MediaPipe encontró algún rostro y sus puntos\n","# 'resultados.multi_face_landmarks' es una lista de los rostros encontrados\n","if resultados.multi_face_landmarks:\n","    print(f\"¡Rostro(s) detectado(s)! Se encontraron puntos faciales.\")\n","\n","    # Tomamos el primer rostro detectado (porque pusimos max_num_faces=1)\n","    rostro = resultados.multi_face_landmarks[0]\n","\n","    # Mostramos cuántos puntos se encontraron en este rostro\n","    print(f\"Cantidad de puntos detectados en el rostro: {len(rostro.landmark)}\")\n","\n","    # Ahora, recorremos cada punto (landmark) detectado en este rostro\n","    # 'rostro.landmark' es la lista de todos los puntos\n","    for id_punto, punto in enumerate(rostro.landmark):\n","        # 'punto' tiene las coordenadas x, y, z (la z es la profundidad, no la usaremos ahora)\n","        # Las coordenadas x e y están normalizadas (entre 0 y 1)\n","\n","        # Convertimos las coordenadas normalizadas a coordenadas de píxeles reales\n","        # Multiplicamos por el ancho o alto de la imagen\n","        coord_x_pixel = int(punto.x * ancho)\n","        coord_y_pixel = int(punto.y * alto)\n","\n","        # Dibujamos un pequeño círculo en la posición del punto sobre la imagen_con_puntos\n","        # cv2.circle(imagen, centro, radio, color, grosor)\n","        # centro: es una tupla (x, y)\n","        # radio: el tamaño del círculo (1 o 2 píxeles es suficiente)\n","        # color: una tupla (B, G, R) - usamos (0, 255, 0) que es Verde en OpenCV\n","        # grosor: -1 significa que rellene el círculo\n","        cv2.circle(imagen_con_puntos, (coord_x_pixel, coord_y_pixel), 2, (0, 255, 0), -1) # Dibujamos un punto verde de radio 2\n","\n","    print(\"Puntos dibujados sobre la imagen.\")\n","\n","    # Finalmente, mostramos la imagen resultante con los puntos dibujados\n","    print(\"\\n--- Imagen con Puntos Faciales ---\")\n","    # Usamos cv2_imshow para mostrar la imagen en Colab\n","    cv2_imshow(imagen_con_puntos)\n","\n","else:\n","    print(\"No se detectaron rostros en la imagen. Intenta con otra imagen o ajusta la confianza de detección.\")\n","\n"],"metadata":{"id":"4hAazmCMKT2x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Conclusión\n","\n","Acabamos de usar herramientas poderosas para detectar y visualizar los puntos clave de un rostro humano. Vimos qué son los landmarks faciales, para qué sirven y cómo podemos encontrarlos con pocas líneas de código gracias a bibliotecas como MediaPipe y OpenCV.\n","\n","Este es solo el comienzo. A partir de estos puntos, se pueden hacer análisis más complejos, como medir la distancia entre los ojos, determinar el ángulo de la cabeza, o incluso empezar a reconocer expresiones."],"metadata":{"id":"3x6vLEmqKbgw"}},{"cell_type":"markdown","source":["## Referencia\n","\n","[Guía de detección de puntos de referencia faciales](https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker?hl=es-419)"],"metadata":{"id":"RMJ6-ftTLL2Y"}}]}